---
title: "Housing Price vs. Supply 2024"
author: Stephanie Armstrong, Ilgaz Kuscu, Alexander D. Silberman, Baylee Wechsler
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
bibliography: references.bib
csl: https://www.zotero.org/styles/apa
---

```{r clear environment}
rm(list=ls())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      root.dir = "C:\\Users\\alexa\\Code\\GW DATS\\6101 Intro to Data Science\\Project 1\\GitHub",
                      warning = F, message = F)
options(scientific = T, digits = 3)
```

```{r libraries}
library(ezids)
library(tidyverse)
library(janitor)
library(scales)
library(ggrepel)
library(corrplot)
library(tigris)
library(sf)
library(ggridges)
library(scales)
library(tidycensus)
library(here)
library(car)
library(dplyr)
library(tibble)
```

## Introduction

Supply and demand is a classic and well-known economic model. However, real life is far more nuanced than the simple version of this model that many are familiar with. We wanted to use real housing price and supply samples to explore how well that relationship fits economic theory. Our research question is: How is the supply of housing related to average home prices across U.S. metropolitan areas in the year 2024?

In 2024, the housing market had more sellers than buyers. Normally, the excess supply in a buyer’s market would place downward pressure on prices, but concurrent economic monetary situation stalled that natural phenomenon. These unusual market conditions make it important to examine their wider economic and social impacts.

Accordingly, the relevance of our question extends beyond economics, since housing prices directly affect households, companies, and wealth inequality. Rising home prices lead to wage increases, which in turn raise the cost of goods and services—creating a vicious cycle that fuels inflation. As uncontrolled inflation deteriorates living standards, companies struggle to attract and retain workers due to reduced labor mobility. Consequently, some firms relocate to more affordable states to balance operational costs.

At the same time, while rising housing costs create financial burdens for renters, homeowners benefit from accumulating wealth through year-over-year appreciation and rental income. In fact, the wealth gap between homeowners and renters has reached a historic high, as housing costs have grown faster than incomes [@urban2023].

Throughout our analysis, we cross-checked our findings with existing research and market reports to better understand these dynamics. In 2024, there were nearly 500000 more sellers than buyers [@redfin2025]. Despite this apparent “buyer’s market,” prices did not decline as economic theory might predict. One possible explanation is that the elasticity of housing supply—the degree to which new construction responds to price changes—has been steadily declining since the Great Recession [@cepr2024].

Additionally, median home prices have more than doubled over the past decade, rising faster than both wages and inflation [@uschamber2024]. This growing affordability crisis hinders job creation, encourages corporate relocations, and causes states to lose billions of dollars in economic output [@pebbcap2024].

## Data
This project uses the State and County Housing Market Indicators dataset from the American Enterprise Institute Housing Center [@aei2024]. The variables are:  

Original Variable Name | New Variable Name | Definition  
  :-: |  :-: | :-- 
State	| State |state
County | County_Name |County
FIPS | FIPS_County_Code | 5-digit Federal Information Processing Series codes (first 2 digits indicate state, last 3 indicate sub-county entity)
Year | Year | Year when the data was collected
Tier | Affordability | Categorizes home sales into entry-level (<=80th percentile of FHA sales prices), move-up (all others), and all
Median.Sale.Price..in.Thousands. | Median_Sale_Price_in_k | Median sale price in thousands of USD per county
House.Price.Appreciation.since.2012 | House_Price_Appreciation_since_2012_percent | Cumulative home price appreciation since 2012
House.Price.Appreciation..Year.over.Year | House_Price_Appreciation_yr_over_yr_percent |Home price appreciation since the previous year
Months..Supply | Months_Supply | Number of months it would take for the inventory of existing homes for sale to be exhausted at the current sales pace
New.Construction.Share.of.Sales | New_Constr_by_share_of_sales_percent | Percent of sales comprising new construction
Mortgage.Default.Rate | Mortgage_Default_Rate_percent | AEI Mortgage Default Rate, a measure of how loans originating in a given month would perform under the same conditions as the 2007 financial crisis (<=7%: Low Risk; between 7.01% and 14%: Medium Risk; >14%: High Risk)

### Data Sources
The AEI Housing Center itself primarily gathered data from public records from First American via Data Tree; specifically, it retrieved data from deed and tax assessor files about where homes were located, their prices, and when the deal took place.

In addition, data for calculating AEI's Mortgage Default Rate were pulled from numerous sources:
- Home Mortgage Disclosure Act (HMDA)
- National Mortgage Default Rate
- CoreLogic’s Loan Level Market Analytics (LLMA)
- ICE’s McDash
- Fannie Mae Single-Family Loan Performance
- Freddie Mac Single Family Loan Level Data
- Federal Housing Association Snapshot

Approximately 60–65% of public records were able to be cross-referenced in this way, though the exact number depends on the locale. These were then weighted up to account for the incomplete data; according to AEI, this is representative of overall public records data

Lastly, data for calculating Months' Supply was taken from Zillow and Realtor.com, and calculated as $\frac{\text{Listings Counts}}{\text{Existing Home Sales.}}$

### Limitations
The weakness of Months' Supply as a proxy for supply should here be noted. Months' Supply may be low for one of two reasons: supply and demand are both high, or supply and demand are both low. As such, it is not ideal for discovering how supply alone affects median sale price. The exact counts, adjusted for population, would be far more useful, 

### Load and Clean Data
```{r read_data}
housing = read.csv("..\\Data\\state_county_data_download_2025.csv")
#dplyr::slice_sample(housing, n = 5) %>% xkabledply()
```

The data is limited to the year 2024, and the variables are renamed for clarity. Additionally, data related to the armed forces are excluded, as that is outside the scope of the research question.

```{r clean_data}
housing_2024 = housing %>% filter(housing$Year == 2024, 
                                  housing$State != 'AA National', 
                                  housing$County != 'AA State') %>% #excluding the armed forces

#rename cols
rename(
  Median_Sale_Price_in_k = Median.Sale.Price..in.Thousands.,
  House_Price_Appreciation_yr_over_yr_percent = House.Price.Appreciation..Year.over.Year.,
  House_Price_Appreciation_since_2012_percent = House.Price.Appreciation.since.2012,
  Months_Supply = Months..Supply,
  New_Constr_by_share_of_sales_percent = New.Construction.Share.of.Sales,
  Mortgage_Default_Rate_percent = Mortgage.Default.Rate,
  County_Name = County,
  FIPS_County_Code = FIPS, 
  Affordability = Tier
)
xkabledplyhead(housing_2024)
```
The typing of the variables is corrected. Some require further processing by removal of the symbols "$", ",", and "%" before they may be cast. Once this is performed, NAs are omitted from *Median_Sale_Price_in_k*; other dependent variables (House Price Appreciation, Mortgage Default Rate) also contained NAs, but, as these were less central to our research question and because we wanted to use as much data as possible, we declined to remove these.

```{r correct_var_typing}
# as factors
housing_2024$State = as.factor(housing_2024$State)
housing_2024$County_Name = as.factor(housing_2024$County_Name)
housing_2024$FIPS_County_Code = as.factor(housing_2024$FIPS_County_Code)
housing_2024$Affordability = as.factor(housing_2024$Affordability)

# remove prefixes '$' and '%' from values
housing_2024 = housing_2024 %>%
  mutate(Median_Sale_Price_in_k = gsub("[\\$,]", "", Median_Sale_Price_in_k),
         House_Price_Appreciation_since_2012_percent =
           gsub("[%,]","",House_Price_Appreciation_since_2012_percent),
         House_Price_Appreciation_yr_over_yr_percent =
           gsub("[%,]","",House_Price_Appreciation_yr_over_yr_percent),
         New_Constr_by_share_of_sales_percent = gsub("[%,]","",New_Constr_by_share_of_sales_percent),
         Mortgage_Default_Rate_percent = gsub("[%,]","",Mortgage_Default_Rate_percent))
###I included the commas to be removed as well indicated in the brackets. SA

#as num instead of chr
housing_2024$Median_Sale_Price_in_k = as.numeric(housing_2024$Median_Sale_Price_in_k)
housing_2024$House_Price_Appreciation_since_2012_percent =
  as.numeric(housing_2024$House_Price_Appreciation_since_2012_percent)
housing_2024$House_Price_Appreciation_yr_over_yr_percent =
  as.numeric(housing_2024$House_Price_Appreciation_yr_over_yr_percent)
housing_2024$New_Constr_by_share_of_sales_percent = 
  as.numeric(housing_2024$New_Constr_by_share_of_sales_percent)
housing_2024$Mortgage_Default_Rate_percent = as.numeric(housing_2024$Mortgage_Default_Rate_percent)
###I included the commas to be removed as well indicated in the brackets. SA

#moving the na dropping to after the parsing
housing_2024 <- housing_2024 %>%
  tidyr::drop_na(Median_Sale_Price_in_k)

#view data
housing_2024 %>% slice_sample(n=5) %>% xkabledply()
```

After cleaning, there are `r housing_2024 %>% nrow()` observations remaining.

However, the presence of the variable *Affordability* means there are three observations associated with each FIPS code: one for Entry-Level homes, one for Move-Up homes, and one that is a combination of the two ("all"). As, for the majority of our purposes, we only want one data point per FIPS code, the dataframe is split in two:
one containing the tiered data (*housing_2024_tiers*), and the second containing only the combined data (*housing_2024_all*).

```{r}
housing_2024_all = housing_2024 %>% filter(housing_2024$Affordability == "all") 

#creating df w/ affordability all totals and then another with entry level/moving up totals
housing_2024_tiers <- housing_2024 %>%
  dplyr::filter(Affordability %in% c("entrylevel","moveup")) %>%
  dplyr::mutate(
    Affordability = factor(Affordability,
                           levels = c("entrylevel","moveup"),
                           labels = c("Entry-Level","Move-Up"))
  )
```

## Exploratory Data Analysis (EDA)

### Summary Statistics

Looking across all U.S. counties in our data set, the typical home price sat at around $200K, though the mean is pulled up by a handful of very expensive markets. Average months of supply was about 3, and well below the 5-6 months that indicate a balanced market. Demand is still outpacing what’s available. 

Despite the tight market, prices rose around 6% year-over-year, and new construction only made up about 6-10% of total sales. Even from the top level data, we can already suspect the pattern: lower supply corresponds with stronger price growth.


```{r summary table all}
#summary stats on new df's
xkablesummary(housing_2024_all)
```


To understand whether that same relationship holds across different parts of the market, we split the data into separate affordability tiers: entry-level and move-up homes, and compared how price and supply interact within each group. 

Entry-level homes were far cheaper, with a typical price around $155K, but the tightest market at about only 2 months of supply. That scarcity was pushing prices up about 6% year-over-year, while new construction made up only about 4% of sales. Builders weren’t adding enough stock to relieve the pressure.

Move-up homes had a median price of more than $400K, doubling the entry-level tier. In contrast, they show a more balanced 5-6 months of supply, slower appreciation at roughly 5%, and far more new construction at about 13%.

Together, these tiers reveal a consistent pattern: markets with tighter supply experience faster price growth, while greater inventory and new construction at the higher end help moderate prices.  


```{r summary table tiers}
#comparing tiers entrylevel and moveup
#entrylevel
xkablesummary(df = subset(housing_2024_tiers, 
                          Affordability == "Entry-Level"),
              title = "Summary Statistics: Entry-Level Homes",
              digits = 2,
              pos = "left",
              bso = "striped")

#moveup
xkablesummary(df = subset(housing_2024_tiers, 
                          Affordability == "Move-Up"),
              title = "Summary Statistics: Move-Up Homes",
              digits = 2,
              pos = "left",
              bso = "striped")
```

### Correlation Heatmap of Numeric Variables

Before we began analyzing specific variables, we constructed a heatmap to see the general magnitude and direction of correlational relationships among our variables. 

```{r corr heatmap}
#correlation heatmap of numeric variables w/ ..._all df
housing_numeric_all <- housing_2024_all %>%
  select(where(is.numeric) & !all_of("Year")) %>%
  drop_na()

cor_matrix_all <- cor(housing_numeric_all)

corrplot(cor_matrix_all, method = "color", 
         type = "lower", 
         tl.cex = 0.7, 
         addCoef.col = "black",
         number.cex=0.6,
         cl.cex = 0.5,
         bg = "transparent")
 
# saves plot
# png(file = "housing_corr_plot.png", type="windows", bg = "transparent")
# 
# corrplot(cor_matrix_all, method = "color", 
#          type = "lower", 
#          # tl.cex = 0.7, 
#          addCoef.col = "black",
#          # number.cex=0.6,
#          #cl.cex = 0.5,
#          bg = "transparent")
# 
# dev.off()
#interesting to see positive and inverse relationships between variables 
#did not scan for no relationships
```

A few notes immediately stand out: some expected, others less so.

House Price Appreciation year over year does not correlate linearly with House Price Appreciation since 2012; it seems like, at least for 2024, it is independent of what came before. Of the two, only one correlates with Median Sale Price: Appreciation since 2012, as expected—the higher the overall appreciation, the higher the price.

New construction correlates with Months’ Supply: the more housing is being built, the longer it’ll take to sell all those houses.

Mortgage Default Rate correlates negatively with Median Sale Price: the lower the sales price, the higher the risk of defaulting on your mortgage—those who can’t afford mortgages purchase less expensive houses.

Surprisingly, Months’ Supply correlates positively with Median Sale Price, not negatively. There is a logical explanation, but only if causality is reversed from our expectations: the higher the price, the longer a home will take to sell. This does, unfortunately, emphasize the flaws in using this dataset to answer our question.

### Price Distributions by Tier

When we compare the price distributions between the tiers, move-up homes clearly sat at the higher level, with a median price about double those of entry-level. With the move-up tier showing more extreme outliers and a much wider range, we can see greater price volatility and a concentration of higher-value counties, confirming that affordability tiers meaningfully segmenting the housing market.
	
Entry-level homes cluster tightly at the lower end, showing limited price variation and reinforcing how constrained the affordability housing stock really is. Together these differences help answer our core question: when supply is tight at the lower end, prices rise fastest there. 

```{r boxplot_price_by_affordability}
#box plotting by affordability tiers from tiers df
housing_afford_box <- ggplot(housing_2024_tiers, 
                             aes(x = Affordability, 
                                 y = Median_Sale_Price_in_k, 
                                 fill = Affordability)) +
  geom_boxplot(width = 0.6, 
               outlier.alpha = 0.25) +
  scale_fill_brewer(palette = "RdYlBu", direction = -1, guide = "none") +
  labs(
    title = "Median Sale Price by Affordability Tier",
     subtitle = "Move-Up homes command higher prices, while Entry-Level markets remain more affordable",
    x = "Affordability Tier",
    y = "Median Sale Price (in thousands)",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal(base_size = 11) +
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        plot.background  = element_blank())

housing_afford_box

#ggsaving
#ggsave(plot = housing_afford_box,
       # filename = "housing_afford_box.png",
       # width = 7,
       # height = 4,
       # dpi = 500,
       # bg = "transparent")
```

### Geographic Price Patterns

Looking at the nation as a whole, we see how home prices vary sharply across regions, revealing a clear geographic divide by affordability. The blues dominate the Midwest and the South, reflecting lower typical prices and more accessible markets, while reds cluster along major metropolitan areas and the coasts, where housing was far more expensive. 

This spatial pattern highlights a regional trend: interior counties remain relatively affordable while coastal regions continue to experience elevated prices. These high-priced areas also tend to align with regions known for limited housing supply and high demand, suggesting that geographic supply constraints are a major factor driving price growth in these markets. 

```{r}
##basemap

#reading in counties spatial file from tigris package
counties_2024 <- counties(year = 2013, 
                          cb = TRUE, 
                          class = "sf",
                          progress_bar = FALSE)

#excluding territories and shifting AK/HI
counties_2024 <- counties_2024 %>%
  filter(as.numeric(STATEFP) < 60) %>%
  shift_geometry()

#removing duplicate columns
counties_2024 <- counties_2024 %>%
  select(-NAME)

#creating basemap and checking
counties_2024_basemap <- ggplot() +
  geom_sf(data = counties_2024) +
  theme_void()

#counties_2024_basemap

##prepping and merging housing_2024_all w/ counties_2024

housing_2024_all <- housing_2024_all %>%
  mutate(price_bin = cut(Median_Sale_Price_in_k,
                         breaks = c(0, 150, 300, 500, 750, 1000, Inf),
                         labels = c("<150k", "150-300k", "300-500k", "500-750k", "750k-1M", ">1M")))

#creating merge df and prepping counties df
housing_merge <- housing_2024_all

counties_2024 <- counties_2024 %>%
  mutate(GEOID = as.numeric(GEOID))

#adding id variables to track observations
counties_2024$id1 <- 1
housing_merge$id2 <- 1

#merging
housing_counties_merge <- merge(x = counties_2024,
                                y = housing_merge,
                                by.x = "GEOID",
                                by.y = "FIPS_County_Code",
                                all = TRUE)

#converting NAs to zeros and finding problem observations
  #looks like it merged just fine
    #i lied, coded wrong and fixed, now i realize theres a  
    #lot of problem observations 

housing_counties_merge <- housing_counties_merge %>%
  mutate(id1 = ifelse(is.na(id1), 0, id1),
         id2 = ifelse(is.na(id2), 0, id2))

no_merge <- housing_counties_merge %>%
  filter(id1 + id2 != 2)

#unique(no_merge$GEOID)

#plotting and checking
# housing_counties_plot <- ggplot() +
#   geom_sf(data = housing_counties_merge,
#           mapping = aes(fill = Median_Sale_Price_in_k),
#           linetype = 0) +
#   #scale_fill_brewer(palette = "GnBi") +
#   theme(legend.position = "none") +
#   theme_void()

#housing_counties_plot

#for fun: trying st_simplify to see if it looks better
housing_counties_merge_simple <- st_simplify(housing_counties_merge, dTolerance = 75)

housing_counties_plot2 <- ggplot() +
  geom_sf(data = housing_counties_merge_simple,
          mapping = aes(fill = price_bin),
          linetype = 0) +
  scale_fill_brewer(palette = "RdYlBu",
                    direction = -1,
                    name = "Median Sale Price",
                    na.value = "grey85") +
  labs(title = "Geographic Variation in U.S. Home Prices, 2024",
       subtitle = "County-level median sale price",
       caption = "Source: American Enterprise Institute") +
  theme_minimal(base_size = 11) +
  theme(plot.title = element_text(face = "bold", 
                                  size = 16),
        plot.subtitle = element_text(size = 12, 
                                     margin = margin(b = 8)),
        plot.caption = element_text(color = "gray40", 
                                    margin = margin(t = 8)),
        legend.title = element_text(face = "bold"),
        legend.position = "right",
        legend.key.height = unit(0.6, "cm"),
        panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        plot.margin = margin(8, 12, 8, 12),
        panel.background = element_rect(fill = "transparent", 
                                        color = NA),
        plot.background  = element_rect(fill = "transparent", 
                                        color = NA))
#+ theme_void()

housing_counties_plot2

# ggsave(plot = housing_counties_plot2,
#        filename = "housing_counties_plot2.png",
#        width = 7,
#        height = 4,
#        dpi = 500,
#        bg = "transparent")
```

### Median Sale Price by State

The first variable we analyzed was median sale price. The distribution of median sale price by state may be visualized as follows: 
```{r}
#boxplotting med sale price by state w/ ..._all df
#all
med_sale_price_by_state_boxplot = ggplot(housing_2024_all, 
                                         aes(x = reorder(State, -Median_Sale_Price_in_k, median), 
                                             y = Median_Sale_Price_in_k)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7) +
  coord_flip() +
  labs(
    title = "Distribution of Median Sale Prices by State (2024)",
    x = "State",
    y = "Median Sale Price (in thousands)",
    caption = "SOURCE: American Enterprise Institute") +
  theme(axis.text.y = element_text(size = 5)) +
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        plot.background = element_blank()) 
#next round, would want to nix outliers
  
med_sale_price_by_state_boxplot
  
# ggsave("med_sale_price_by_state_boxplot.png", plot = med_sale_price_by_state_boxplot, 
#        width = 10, height = 10, dpi = 300)
```

This graph allowed us to see the trend of median sale price distribution among states. However, the graph is too busy to be particularly useful. You can see general trends, but a smaller sample improves legibility.

### Top and Bottom Months' Supply Analysis 

We subsetted the dataset in order to have a smaller sample to visualize and analyze our data. By isolating the states with the highest and lowest Months' Supply, we were able to better visualize the difference in how Months' Supply correlates with other variables of interest.

The states that fell into these groups are:  
```{r}
#boxplotting with new df: ..._all
#Find top/bottom 5 by median Months' Supply, not row count
states_by_median_months_supply <- housing_2024_all %>%
  group_by(State) %>%
  summarize(Median_Months_Supply = median(Months_Supply))

top_states_all = states_by_median_months_supply %>% slice_max(order_by = Median_Months_Supply, n = 5)

bottom_states_all <- states_by_median_months_supply %>% slice_min(order_by = Median_Months_Supply, n = 5)

#merge top and bottom states
housing_compare_all <- housing_2024_all %>%
  filter(State %in% c(top_states_all$State, bottom_states_all$State)) %>%
  mutate(StateGroup = case_when(
    State %in% top_states_all$State ~ "High Months' Supply",
    State %in% bottom_states_all$State ~ "Low Months' Supply")) %>%
  mutate(StateGroup = factor(StateGroup, levels = c("Low Months' Supply", "High Months' Supply")))
```

#### Top Months' Supply States
```{r top-months-supply-states}
top_states_all %>% 
  add_column(State_Name = c("Hawaii","District of Columbia", "Florida", "Colorado", "Oregon")) %>%
  relocate(State_Name, .after = State) %>%
  xkabledply
```

#### Bottom Months' Supply States	
```{r bottom-months-supply-states}
bottom_states_all %>% 
  add_column(State_Name = c("Massachusetts","Wisconsin", "Kentucky", 
                            "New Hampshire", "Illinois","Indiana","Mississippi",
                            "North Dakota","Ohio")) %>%
  relocate(State_Name, .after = State) %>%
  xkabledply
```

Immediately, the subsetted data in the same graph format shows a much clearer vision of the positive association between months' supply and median sale price.

```{r top bottom hist price}
#is prep for the all states factored scatter but 
#fix color assigning for side by side compare scatterplots- too many blue showing up
#cleaned plot version with dropped unused (non-10) state levels; re-group by state for clarity
housing_compare_all_plot <- housing_compare_all %>%
  group_by(State, StateGroup) %>%
  summarize(
    Median_Sale_Price_in_k = median(Median_Sale_Price_in_k, na.rm = TRUE),
    Months_Supply = median(Months_Supply, na.rm = TRUE),
    .groups = "drop") %>%
  mutate(State = forcats::fct_drop(State))

#also fixing subset of housing 2024 all so that gray background dots are 1/state
housing_2024_all_plot <- housing_2024_all %>%
  group_by(State) %>%
  summarize(
    Median_Sale_Price_in_k = median(Median_Sale_Price_in_k, na.rm = TRUE),
    Months_Supply = median(Months_Supply, na.rm = TRUE),
    .groups = "drop")

#label points for 10 states 
label_points_all <- housing_compare_all_plot

#using cleaned version of plot data to assign colors
top_states_colors_all <- scales::seq_gradient_pal("lightblue", "darkslateblue")(seq(0, 1, length.out = length(unique(housing_compare_all_plot$State[housing_compare_all_plot$StateGroup == "High Months' Supply"]))))
names(top_states_colors_all) <- unique(housing_compare_all_plot$State[housing_compare_all_plot$StateGroup == "High Months' Supply"])

bottom_states_colors_all <- scales::seq_gradient_pal("lightpink", "darkred")(seq(0, 1, length.out = length(unique(housing_compare_all_plot$State[housing_compare_all_plot$StateGroup == "Low Months' Supply"]))))
names(bottom_states_colors_all) <- unique(housing_compare_all_plot$State[housing_compare_all_plot$StateGroup == "Low Months' Supply"])

state_colors_all <- c(top_states_colors_all, bottom_states_colors_all)

#boxplotting med sale price by state w/ ..._compare_all df
#all
ggplot(housing_compare_all, aes(x = reorder(State, Median_Sale_Price_in_k, median), 
                         y = Median_Sale_Price_in_k,
                         fill = State)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = state_colors_all) +  
  coord_flip() +
  labs(
    title = "Distribution of Median Sale Prices by States with\nExtreme Months' Supply (2024)",
    x = "State",
    y = "Median Sale Price (in thousands)",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        plot.background = element_blank()) 
```

We also looked at the distribution of the subset of states' months' supply of housing.

```{r hist supply}
#hist of Months' Supply
supply12hist <- ggplot(housing_compare_all, 
       aes(x = reorder(State, Months_Supply, median),
           y = Months_Supply,
           fill = State)) +  
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = state_colors_all) +  
  coord_flip() +
  labs(title = "Distribution of Months' Supply by States with\nExtreme Months' Supply (2024)",
    x = "State",
    y = "Months' Supply",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 14, margin = margin(b = 3)),
    plot.subtitle = element_text(size = 10, color = "gray25", margin = margin(b = 8)),
    axis.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 9),
    plot.caption = element_text(size = 8, color = "gray40", hjust = 1),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    plot.background = element_blank())

# ggsave("housing_supply_12_hist.png", plot = supply12hist, width = 10, height = 6, dpi = 300)

supply12hist

#needs a subtitle with commentary, just remembered all need a caption with the source named, and we can prob add other elements to this, because otherwise it seems to obvi to me

#some other supply dist graph? full 50 I think

#z score
#confidence interval (on what tho, maybe median sale price and Months' Supply)
#then add Zscore and CI onto scatterplot somehow?
```

As you can see, there is over a six month difference in supply of housing between the states with the lowest and highest counts (Massachusetts and Hawaii). 

We also see that a few of the states have significant outliers, like North Dakota, for example. North Dakota closely aligns with a few of the lower supply states, but higher outliers pull the median forward. For our next round of analysis, we may choose to pursue excluding outliers to see how that changes the findings. 

The following graph also highlights the relationship between our price and supply variables.

```{r top bottom boxplot price supply dist, factored}
#plot top bottom comparison ####
med_sale_price_in_states_by_months_supply_boxplot <- ggplot(
  housing_compare_all, 
  aes(x = reorder_within(State, Median_Sale_Price_in_k, StateGroup), 
    y = Median_Sale_Price_in_k,
    fill = StateGroup)) +
  geom_boxplot() +
  facet_wrap(~ StateGroup, scales = "free_x") +
  scale_x_reordered()  +
  labs(
    title = "Median Sale Price in States by Months' Supply of Housing",
    subtitle = "The Median Sale Price in States with a Larger Months' Supply of Housing is Significantly Lower\nthan States with a Smaller Months' Supply of Housing",
    x = "State",
    y = "Median Sale Price (in thousands)",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal() +
  scale_fill_manual(values = c("High Months' Supply" = "skyblue", "Low Months' Supply" = "red"))+
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        plot.background = element_blank()) 

med_sale_price_in_states_by_months_supply_boxplot

# ggsave("med_sale_price_in_states_by_months_supply_boxplot.png", 
#        plot = med_sale_price_in_states_by_months_supply_boxplot, width = 10, height = 10, dpi = 300)
```
### Scatterplot of Months' Supply and Median Price

We also visualized this comparison with a scatterplot of all 50 states and D.C. Looking at the scatterplot results, the positive association between median sale price and months' supply is plainly visible.
```{r 51 state supply price scatter}
#this chunk contains the all states unfactored scatter
#compare color scale w/ ..._all df

#now actual plot
allstatescatterplot <- ggplot(housing_2024_all_plot, aes(x = Months_Supply, y = Median_Sale_Price_in_k)) +
  geom_point(color="steelblue", alpha = 0.7) +
  # geom_smooth(method = "lm", se = FALSE, color = "black") +
  labs(
    title = "Months' Supply of Housing vs Median Sale Price",
    subtitle= "A Scatterplot Reveals a Positive Correlation Between Months' Supply\nof Housing and Median Sale Price",
    x = "Months of Supply",
    y = "Median Sale Price (in thousands)",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        plot.background = element_blank()) 

# ggsave("housing_supply_vs_price_allstates.png", plot = allstatescatterplot, width = 10, height = 6, dpi = 300)

allstatescatterplot
```

```{r mystery}
#hist plotting with df ..._all
#housing_price_hist <- ggplot(housing_2024_all, aes(x = Median_Sale_Price_in_k)) +
#  geom_histogram(binwidth = 25, fill = "skyblue", color = "black") +
#  scale_x_continuous(labels = scales::dollar_format(prefix = "$", suffix = "k")) +
#  labs(
#    title = "Distribution of Median Sale Prices",
#    subtitle = "Most U.S. counties cluster below $300k, with a long right-skewed tail #in higher-priced markets",
#    x = "Median Sale Price (in thousands)",
#    y = "Number of Counties",
#    caption = "SOURCE: American Enterprise Institute") +
#  theme_minimal() +
#  theme(plot.title = element_text(face = "bold", 
#                                  size = 14, 
#                                  margin = margin(b = 3)),
#        plot.subtitle = element_text(size = 10, 
#                                     color = "gray25",
#                                     margin = margin(b = 8)),
#        axis.title = element_text(size = 10, 
#                                  face = "bold"),
#        axis.text = element_text(size = 9),
#        plot.caption = element_text(size = 8, 
#                                    color = "gray40", 
#                                    hjust = 1),
#        panel.grid.minor = element_blank(),
#        panel.background = element_blank(), 
#        plot.background = element_blank()) #

#ggsaving
#ggsave(plot = housing_price_hist,
#       filename = "housing_price_hist.png",
#       width = 7,
#       height = 4,
#       dpi = 500,
#       bg = "transparent")
#
#needs a subtitle with commentary, just remembered all need a caption with the source named, and we can prob add other elements to this, because otherwise it seems to obvi to me
```

We also wanted to separate out our subsetted data and overlay it onto the map above. In the following scatterplot, we see a striking trend revealed from the overlays of the subsetted scatter plots onto the 50 states and D.C. scatterplot. The association between months' supply and median sale price is glaringly obvious in this graph. 

```{r scatter_supply_vs_median_price total all}
#all in gray with faceted compare in color with states labeled ####
tierhighlightscatterplot <- ggplot() +
  geom_point(data = housing_2024_all_plot, aes(x = Months_Supply, y = Median_Sale_Price_in_k),
             color = "gray70", alpha = 0.3, size = 1.5) +
  geom_point(data = housing_compare_all_plot,
             aes(x = Months_Supply, y = Median_Sale_Price_in_k, color = State),
             size = 1.5, alpha = 0.9) +
  geom_text_repel(data = label_points_all,
                  aes(x = Months_Supply, y = Median_Sale_Price_in_k, 
                      label = State),
                  size = 3.5, color= "black", stroke=0.01, segment.color = NA, segment.size = 0.3,
                  segment.alpha = 1, min.segment.length = 0, show.legend = FALSE) +
  facet_wrap(~ StateGroup) +
  scale_color_manual(values = state_colors_all) +
  labs(
    title = "Months' Supply vs Median Price by State",
    subtitle = "The positive association between Months' Supply and High Median Sale Price is Immediately Visible",
    x = "Months of Supply",
    y = "Median Sale Price (in thousands)",
    color = "State",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal()+
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        plot.background = element_blank()) 

# ggsave("housing_supply_vs_price_tierhighlight.png", plot = tierhighlightscatterplot, width = 10, height = 6, dpi = 300)

tierhighlightscatterplot
```

```{r}
#both together in gray with compare in color with states labeled w/ ..._all df
#ggplot() +
#  geom_point(data = housing_2024_all, 
#             aes(x = Months_Supply, y = Median_Sale_Price_in_k), 
#             color = "gray70", alpha = 0.3, size = 1) +
  # geom_path(data = housing_compare %>% filter(StateGroup == "States with the Most Houses"),
  #           aes(x = Months_Supply, y = Median_Sale_Price_in_k, group = State, color = State),
  #           alpha = 0.8, size = 1) +
#  geom_point(data = housing_compare_all %>% filter(StateGroup == "States with the Most Houses"),
#             aes(x = Months_Supply, y = Median_Sale_Price_in_k, color = State),
#             alpha = 0.5, size = 2) +
#  # geom_path(data = housing_compare %>% filter(StateGroup == "States with the Fewest Houses"),
  #           aes(x = Months_Supply, y = Median_Sale_Price_in_k, group = State, color = State),
  #           alpha = 0.8, size = 1) +
 # geom_point(data = housing_compare_all %>% filter(StateGroup == "States with the Fewest Houses"),
 #            aes(x = Months_Supply, y = Median_Sale_Price_in_k, color = State),
#             alpha = 0.5, size = 2) +
#  scale_color_manual(values = state_colors_all) +
#  labs(
 #   title = "Housing Supply vs Median Price: All Counties with Highlights",
#    subtitle = "Gray points: All counties | Blue shades: States with Most Houses | Red shades: States with Fewest Houses",
#    x = "Months of Supply",
 #   y = "Median Sale Price (in thousands)",
  #  color = "State",
#    caption = "SOURCE: American Enterprise Institute") +
#  theme_minimal()
```

```{r}
#housing_constr_all = housing_2024_all
#housing_constr_all = housing_constr_all %>% 
#  mutate(constr_bins = cut(New_Constr_by_share_of_sales_percent, breaks=10))

#ggplot(housing_constr_all, aes(x = constr_bins, y = Median_Sale_Price_in_k, fill=constr_bins)) +
#  geom_boxplot() +
 # labs(
#    title = "Median Sale Price by Percent New Construction (2024)",
#    x = "New Construction by Share of Sales Percent",
#    y = "Median Sale Price (in thousands)",
#    caption = "SOURCE: American Enterprise Institute") +
#  theme_minimal()

# Perhaps new construction indicates high demand, and as such, the more new construction, the higher the median sale price?
#I would like to know which states fall into these buckets. In which states are the top quarter and bottom quarter? BW
#I'm going to break this into smaller buckets and investigate.BW
```

In this final visualization, we overlayed the median sale price, represented by black dots, with the monetary values along the top x axis onto the county distributions of months supply on the bottom x axis across the states in our subsetted dataset. 

There is a clear trend in higher months' supply correlating with higher median sale price. We also see a few states where outliers skew the median sale price- this is most obvious for Massachusetts and New Hampshire. 

Another important note is that, for readability, the graph data was capped at 12 months. New Hampshire has several counties where the months supply value is higher than is visible in this graph, and this helps explain what otherwise appears to bea right-skewed median sale price.

```{r supply option 2- 12}
#housing supply dist w 12 states for context, all df

#prep
max_months <- 12
housing_ridge <- housing_compare_all %>%
  mutate(Months_Supply_Capped = pmin(Months_Supply, max_months))

#medians per state
state_medians <- housing_ridge %>%
  group_by(State) %>%
  summarize(
    Median_Sale_Price = median(Median_Sale_Price_in_k, na.rm = TRUE),
    .groups = "drop"
  )

#normalize sale price to match the x-axis range (e.g. 0–12 months)
sale_price_min <- min(state_medians$Median_Sale_Price, na.rm = TRUE)
sale_price_max <- max(state_medians$Median_Sale_Price, na.rm = TRUE)

#normalize price into 0-12 scale
scale_price_to_months <- function(price_k) {
  scales::rescale(price_k, to = c(0, max_months), from = c(sale_price_min, sale_price_max))
}

#apply scaled value
state_medians <- state_medians %>%
  mutate(Scaled_Sale_Price = scale_price_to_months(Median_Sale_Price))

#reorder
state_order <- state_medians %>%
  arrange(Median_Sale_Price) %>%
  pull(State)
housing_ridge <- housing_ridge %>%
  mutate(State = factor(State, levels = state_order))

#save plot as object
supplyridge_12medianprice_plot <- ggplot(housing_ridge, aes(x = Months_Supply_Capped, y = State, fill = StateGroup), fill = StateGroup) +
  geom_density_ridges(scale = 1.5, alpha = 0.8, color = "white") +
  geom_point(data = state_medians, 
             aes(x = Scaled_Sale_Price, y = State), 
             inherit.aes = FALSE,
             shape = 21, fill = "black", color = "white", size = 2) +
  scale_fill_manual(values = c("Low Months' Supply" = "indianred", "High Months' Supply" = "steelblue")) +
  scale_x_continuous(
    name = "Months of Supply (capped at 12)",
    sec.axis = sec_axis(
      trans = ~ scales::rescale(., to = c(sale_price_min, sale_price_max), from = c(0, max_months)),
      name = "Median Sale Price (in thousands)",
      labels = dollar_format(prefix = "$", suffix = "k"))) +
  labs(
    title = "Distribution of Months' Supply by State with Median Sale Price Overlay",
    subtitle = "Each ridge shows the supply distribution for a state; black dots show scaled median sale prices",
    y = "State",
    fill = "State Group",
    caption = "SOURCE: American Enterprise Institute") +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.title.x.top = element_text(margin = margin(b = 10)))+
  theme(plot.title = element_text(face = "bold", 
                                  size = 14, 
                                  margin = margin(b = 3)),
        plot.subtitle = element_text(size = 10, 
                                     color = "gray25",
                                     margin = margin(b = 8)),
        axis.title = element_text(size = 10, 
                                  face = "bold"),
        axis.text = element_text(size = 9),
        plot.caption = element_text(size = 8, 
                                    color = "gray40", 
                                    hjust = 1),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        plot.background = element_blank()) 

# ggsave("supply_ridge_12_saleprice_plot.png", plot = supplyridge_12medianprice_plot, width = 10, height = 6, dpi = 300)

supplyridge_12medianprice_plot
```

## Significance Testing

Though the graphs have proven quite conclusive, we proceed with ANOVA testing to confirm the existence of and nature of the relationship between our variables.

$H_0: \mu_{AK} = \mu_{AL} = ... = \mu_{WY}$

$H_1:$ At least one $\mu$ is different

```{r anova}
states_median_sale_price_anova = aov(Median_Sale_Price_in_k ~ State, data = housing_2024_all)
xkabledply(states_median_sale_price_anova, title = "ANOVA result summary")
```

Median sale price varies highly significantly by state, with a p-value smaller than r can store. As such, we reject the null hypothesis, concluding that it is improbable that states have the same true median sale price.

### Post-hoc Tukey HSD

It is best practice to follow a significant ANOVA with a post-hoc Tukey HSD; as there are 2550 possible pairings, rather than display the full output, we will instead list all of the pairwise combinations which have a P-value less than 0.05, of which there are 550:

```{r median_sale_price_tukey_hsd}
states_median_sale_price_tukey <- TukeyHSD(states_median_sale_price_anova)
states_median_sale_price_tukey$State[, "p adj"] %>%
  subset(states_median_sale_price_tukey$State[, "p adj"] < 0.05)
```


## Conclusion 
In conducting this project, our team was reminded of our first day of class, going over the data science life cycle. We initially established a question we wanted to answer and identified data that we believed could enlighten us on this data. However, by conducting our EDA, we discovered that the metrics that AEI chose to include do not directly match the question we sought out to answer.

### Key Takeaways
There is a clear connection between months supply of housing and median sale price. This could be due to high demand pushing sale prices higher or low supply pushing sale prices higher. We will need more data in order to identify which is the stronger driver, if either. 

We also found interesting connections between the percent of houses in a county that are new constructions and the mortgage default rate in a county with our two key variables, months supply and median sale price. 

### Next Steps
One next step for us might be to pull in additional data to help us add color to the picture we are painting and to also help us better address our original research question. We will need to do additional analysis to better identify the nature of the relationship between these primary and secondary variables. 

We could also take straight from the source and attempt to pull public records data from First American via Data Tree and listings counts from Zillow and Realtor.com, perhaps adjusting for population. This would be a much better representation of supply than Months' Supply.

## References



# project 2 ####

## Data

### Data Sources

#### American Community Survey

```{r load_acs}
census_api_key("29e7dfea2f8b253a0a10ccd9626f78e49f4f0a4f")

census_vars = load_variables(year = 2024, dataset = "acs1/profile", cache = TRUE)
census_vars_limited = grepv("^(?!DP02PR).*P$", census_vars$name, perl=TRUE)
acs1_2024 = get_acs(geography = "metropolitan statistical area/micropolitan statistical area",
                    variables = census_vars_limited,
                    year = 2024,
                    survey = "acs1",
                    output = "wide")
head(acs1_2024)
```

The list of variables includes what should be the total population as a percent—"DP05_0001P"—but, as that would always be 100%, the wise people at the US Census Bureau made such equal to "DP05_0001E", the total population estimate, necessitating no further adjustment.

This includes both percents as well as margins of error. I have included code to drop the margins of error, but I am unsure if this is a good idea.

#### Realtor.com

```{r load_realtor}
#loading in inventory data
inventory_raw <- read_csv(here("../data/RDC_Inventory_Core_Metrics_Metro_History.csv"))

#cleaning names
clean_names(inventory_raw)

#hunting down year
glimpse(inventory_raw)

#filtering for 2024
inventory_2024 <- inventory_raw %>%
  filter(month_date_yyyymm >= 202401 & month_date_yyyymm <= 202412)

#filtered for target vars
inventory_2024_filtered <- inventory_2024%>%
  select(
    month_date_yyyymm,
    cbsa_code,
    cbsa_title,
    HouseholdRank,
    median_listing_price_per_square_foot,
    total_listing_count,
    pending_ratio,
    median_days_on_market)%>%
  mutate(
    log_median_price_sqft = log(median_listing_price_per_square_foot))

summary(inventory_2024_filtered)
```


The Realtor.com inventory dataset provides monthly metro-level housing indicators like listing counts, median prices, and days on market. Unlike the ACS, it doesn’t include paired estimates or margins of error. Each variable is already given as a direct point estimate. Some fields (the _mm and _yy columns) represent month-over-month or year-over-year percent changes, which introduce redundancy, so we later drop those before modeling. Aside from that, the data only need to be filtered to the 2024 months and are ready for use.


```{r dropping margins of error}
acs1_2024_pcts = select(acs1_2024, -grepv("M$", names(acs1_2024)))
head(acs1_2024_pcts)
```


```{r ilgaz' correlation check & steph's attempt at multiColl detection}
#ilgaz' correlation stuff
# acs_clean <- acs1_2024_pcts %>% drop_na()
# num_df <- acs_clean %>% 
#   select(where(is.numeric))
# num_df$dummy_target <- rnorm(nrow(num_df))
#model <- lm(dummy_target ~ ., data = num_df)
#check_collinearity(model)

# head(acs_clean)
# num_df <- acs1_2024_pcts %>% select(where(is.numeric))
# 
# corr_mat <- cor(num_df, use = "pairwise.complete.obs")
# threshold <- 0.80
# 
# high_corr <- which(abs(corr_mat) > threshold,
#                    arr.ind = TRUE)
# 
# # convert to readable table
# high_corr_pairs <- data.frame(
#   var1 = rownames(corr_mat)[high_corr[,1]],
#   var2 = colnames(corr_mat)[high_corr[,2]],
#   corr = corr_mat[high_corr]
# )
# 
# # remove duplicates (since matrix is symmetric)
# high_corr_pairs <- high_corr_pairs[high_corr_pairs$var1 < high_corr_pairs$var2, ]
# 
# 
# high_corr_pairs # 2794 out of 147,696 pairs (around 2%) have an absolute corr >= .80
# 
# #steph's sidequest
# sq_acs <- acs1_2024_pcts
# 
# #numeric-only subset
# sq_acs_num <- sq_acs %>%
#   select(where(is.numeric))
# 
# #ID'ing fake percents and set to na
# sq_acs_num <- sq_acs_num %>%
#   mutate(across(everything(),
#                 ~ ifelse(. > 100, NA, .)))
# 
# #dropping all na columns
# sq_acs_num <- sq_acs_num %>%
#   select(where(~ !all(is.na(.))))
# 
# #converting NA values to median
# sq_acs_num <- sq_acs_num %>%
#   mutate(across(everything(),
#                 ~ ifelse(is.na(.),
#                          median(., na.rm = TRUE),
#                          .)))
# 
# #dropping constant or near-constant cols
# sq_acs_num <- sq_acs_num %>%
#   select(where(function(col) {
#     s <- sd(col, na.rm = TRUE)
#     if (is.na(s)) s <- 0
#     s > 10
#   }))
# 
# #dummy target
# set.seed(123)
# sq_acs_num$fake <- rnorm(nrow(sq_acs_num))
# 
# #fitting dummy linear model
# sq_acs_mod <- lm(fake ~ ., data = sq_acs_num)
# 
# #computing vif
# compute_vif <- function(df){
#   vars <- colnames(df)
#   out <- tibble(variable = vars, vif = NA_real_)
#   
#   for(i in seq_along(vars)){
#     y <- df[[i]]
#     X <- df[, -i, drop = FALSE]
#     
# #fit model for this variable alone
#   mod <- tryCatch(lm(y ~ ., data = as.data.frame(X)),
#                     error = function(e) NULL)
#     
#     if(!is.null(mod)){
#       out$vif[i] <- tryCatch(
#         max(car::vif(mod)),
#         error = function(e) NA_real_
#       )
#     }
#   }
#   
#   out
# }
# 
# vif_results <- compute_vif(sq_acs_num)
# 
# #sort highest VIF at top
# vif_results_sorted <- vif_results %>% arrange(desc(vif))
# 
# vif_results_sorted

```


```{r future ACS variable dictionary}
#ACS variable codes 
#use to make a dictionary for the report

#demographics

#DP05_0001E - Total Population

#DP05_0003PE – % Female
#DP05_0037PE – % White alone
#DP05_0045PE – % Black or African American alone
#DP05_0053PE - % American Indian and Alaska Native alone
#DP05_0061PE – % Asian alone
#DP05_0069PE - % Native Hawaiian and Other Pacific Islander alone
#DP05_0075PE - % Two or More Races

#DP05_0090PE – % Hispanic or Latino

#DP05_0018E - Median age (years)
#DP05_0019PE - % Under 18 years

#households

#DP02_0001E – Total households
#DP02_0002PE – % Married-couple households
#DP02_0006PE – % Male householder, no spouse
#DP02_0010PE – % Female householder, no spouse

#economics

#DP03_0005PE – % Unemployed
#DP03_0119PE – % Below poverty level

#DP03_0052PE - % Household income <$10,000
#DP03_0053PE - % Household income $10,000 to $14,999
#DP03_0054PE - % Household income $15,000 to $24,999
#DP03_0055PE - % Household income $25,000 to $34,999
#DP03_0056PE - % Household income $35,000 to $49,999
#DP03_0057PE - % Household income $50,000 to $74,999
#DP03_0058PE – % Household income $75,000 to $99,999
#DP03_0059PE – % Household income $100,000 to $149,999
#DP03_0060PE – % Household income $150,000 to $199,999
#DP03_0061PE – % Household income $200,000 or more

#DP03_0062E - Median household income (dollars)

#DP02_0067PE - % High school graduate or higher
#DP02_0068PE – % Bachelor’s degree or higher


#housing

#DP04_0001E – Total housing units
#DP04_0003PE – % Vacant units

#DP04_0046PE – % of occupied that are Owner-occupied

#DP04_0017PE - % Units built 2020 or later
#DP04_0018PE - % Units built 2010 to 2019
#DP04_0019PE – % Units built 2000 to 2009
#DP04_0020PE – % Units built 1990 to 1999
#DP04_0021PE – % Units built 1980 to 1989
#DP04_0022PE – % Units built 1970 to 1979
#DP04_0023PE – % Units built 1960 to 1969
#DP04_0024PE – % Units built 1950 to 1959
#DP04_0025PE – % Units built 1940 to 1949
#DP04_0026PE – % Units built 1939 or earlier

#DP04_0039PE - % 0 Bedrooms
#DP04_0040PE - % 1 Bedrooms
#DP04_0041PE - % 2 Bedrooms
#DP04_0042PE - % 3 Bedrooms
#DP04_0043PE - % 4 Bedrooms
#DP04_0044PE - % 5 Bedrooms or more
```


```{r filter acs data down}
#which variables to keep
vars_needed <- c("DP05_0001E", 
                 "DP05_0003PE", 
                 "DP05_0037PE", 
                 "DP05_0045PE", 
                 "DP05_0053PE", 
                 "DP05_0061PE", 
                 "DP05_0069PE", 
                 "DP05_0075PE", 
                 "DP05_0090PE", 
                 "DP05_0018E", 
                 "DP05_0019PE", 
                 "DP02_0001E", 
                 "DP02_0002PE", 
                 "DP02_0006PE", 
                 "DP02_0010PE", 
                 "DP03_0005PE", 
                 "DP03_0119PE", 
                 "DP03_0052PE", 
                 "DP03_0053PE", 
                 "DP03_0054PE", 
                 "DP03_0055PE", 
                 "DP03_0056PE", 
                 "DP03_0057PE", 
                 "DP03_0058PE", 
                 "DP03_0059PE",
                 "DP03_0060PE", 
                 "DP03_0061PE", 
                 "DP03_0062E",
                 "DP02_0067PE", 
                 "DP02_0068PE",
                 "DP04_0001E", 
                 "DP04_0003PE", 
                 "DP04_0046PE",
                 "DP04_0017PE", 
                 "DP04_0018PE",
                 "DP04_0019PE", 
                 "DP04_0020PE",
                 "DP04_0021PE", 
                 "DP04_0022PE", 
                 "DP04_0023PE", 
                 "DP04_0024PE",
                 "DP04_0025PE", 
                 "DP04_0026PE",
                 "DP04_0039PE", 
                 "DP04_0040PE", 
                 "DP04_0041PE",
                 "DP04_0042PE", 
                 "DP04_0043PE", 
                 "DP04_0044PE")

#filter down the dataset
acs1_2024_filtered <- acs1_2024_pcts[, c("GEOID", "NAME", vars_needed)]

#rename ACS variable codes to real things
acs1_2024_filtered <- acs1_2024_filtered %>%
  rename(total_population = DP05_0001E,
    pct_female = DP05_0003PE,
    pct_white = DP05_0037PE,
    pct_black = DP05_0045PE,
    pct_aian = DP05_0053PE,
    pct_asian = DP05_0061PE,
    pct_nhpi = DP05_0069PE,
    pct_two_or_more = DP05_0075PE,
    pct_hispanic = DP05_0090PE,
    median_age = DP05_0018E,
    pct_under_18 = DP05_0019PE,
    total_households = DP02_0001E,
    pct_married_couple = DP02_0002PE,
    pct_male_householder = DP02_0006PE,
    pct_female_householder = DP02_0010PE,
    pct_unemployed = DP03_0005PE,
    pct_below_poverty = DP03_0119PE,
    pct_income_lt10k = DP03_0052PE,
    pct_income_10_14999 = DP03_0053PE,
    pct_income_15_24999 = DP03_0054PE,
    pct_income_25_34999 = DP03_0055PE,
    pct_income_35_49999 = DP03_0056PE,
    pct_income_50_74999 = DP03_0057PE,
    pct_income_75_99999 = DP03_0058PE,
    pct_income_100_149k = DP03_0059PE,
    pct_income_150_199k = DP03_0060PE,
    pct_income_200k_plus = DP03_0061PE,
    median_household_income = DP03_0062E,
    pct_high_school_plus = DP02_0067PE,
    pct_bachelors_plus = DP02_0068PE,
    total_housing_units = DP04_0001E,
    pct_vacant_units = DP04_0003PE,
    pct_owner_occupied = DP04_0046PE,
    pct_built_2020_plus = DP04_0017PE,
    pct_built_2010_2019 = DP04_0018PE,
    pct_built_2000_2009 = DP04_0019PE,
    pct_built_1990_1999 = DP04_0020PE,
    pct_built_1980_1989 = DP04_0021PE,
    pct_built_1970_1979 = DP04_0022PE,
    pct_built_1960_1969 = DP04_0023PE,
    pct_built_1950_1959 = DP04_0024PE,
    pct_built_1940_1949 = DP04_0025PE,
    pct_built_1939_earlier = DP04_0026PE,
    pct_0_bed = DP04_0039PE,
    pct_1_bed = DP04_0040PE,
    pct_2_bed = DP04_0041PE,
    pct_3_bed = DP04_0042PE,
    pct_4_bed = DP04_0043PE,
    pct_5plus_bed = DP04_0044PE)

# #check it out
head(acs1_2024_filtered)

# remove a few collinear / unusable vars
# acs1_2024_filtered <- acs1_2024_filtered %>%
#   select(-pct_male,
#          -pct_hispanic,
#          -pct_65_over,
#          -pct_renter_occupied)

#I want to make a area type var here before merging 
#create area_type var
acs1_2024_filtered <- acs1_2024_filtered %>%
  mutate(area_type = ifelse(grepl("Micro Area",NAME), "Micro", "Metro"))

unique(acs1_2024_filtered$area_type)
```


```{r merge datasets & clean}
#cbsa code var to chr so merge works
inventory_2024 <- inventory_2024 %>%
  mutate(cbsa_code = as.character(cbsa_code))

#merge ACS and inventory datasets
full_dataset <- acs1_2024_filtered %>%
  left_join(inventory_2024, by = c("GEOID" = "cbsa_code"))

#which vars to factor
factor_vars <- c("GEOID",
  "NAME",
  "cbsa_title",
  "HouseholdRank",
  "quality_flag",
  "area_type")

#drop redundant columns
redundant_vars <- full_dataset %>%
  select(ends_with("_mm"), ends_with("_yy")) %>%
  names()

#clean dataset
full_dataset_clean <- full_dataset %>% # Drop redundant columns
  select(-all_of(redundant_vars)) %>% # Convert factor variables
  mutate(across(all_of(factor_vars), as.factor)) %>% # Log home price
  mutate(log_median_listing_price = log(median_listing_price)) 

#NAs by variable type
na_summary_one <- full_dataset_clean %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "NA_count") %>%
  mutate(var_type = ifelse(variable %in% factor_vars, "factor", "numeric")) %>%
  arrange(desc(NA_count))

print(na_summary_one)

```


```{r NAs}
#address NAs (drop hispanic, when organized by FIPS code, nearest neighbor for ages, replace remaining NAs with 0)
#drop hispanic
#commenting out for now since some of this was done earlier and would like to convene before moving/removing
# full_dataset_clean <- full_dataset_clean %>%
#   select(-pct_hispanic)
# 
# #when organized by FIPS code, nearest neighbor for ages
# age_vars <- c("pct_under_18", "pct_65_over")
# 
# full_dataset_clean <- full_dataset_clean %>%
#   arrange(GEOID, month_date_yyyymm) %>%
#   group_by(GEOID) %>%
#   mutate(across(all_of(age_vars), 
#                 ~ if(sum(!is.na(.)) >= 2) {
#                     approx(x = seq_along(.), 
#                            y = ., 
#                            xout = seq_along(.), 
#                            method = "linear", 
#                            rule = 2)$y
#                   } else {
#                     .  # leave as-is (NA)
#                   })) %>%
#   ungroup()
# 
# na_counts_two <- full_dataset_clean %>%
#   summarise(across(everything(), ~ sum(is.na(.)))) %>%
#   pivot_longer(everything(), names_to = "variable", values_to = "na_count") %>%
#   arrange(desc(na_count))
# 
# na_counts_two
```


```{r NAs 2}
#the age percentages don't make sense, so I'm deleting them. If we want to factor age in later, we can go back and fix this, but I am not in the mood atm. 
#commenting out for now since this was done earlier 
# full_dataset_clean <- full_dataset_clean %>%
#   select(-pct_under_18, -pct_65_over)
# 
# #also removing redundant columns
# full_dataset_clean <- full_dataset_clean %>%
#   select(
#     -pct_male,               
#     -pct_male_householder)

#remove remaining NAs
full_dataset_clean <- full_dataset_clean %>%
  drop_na()
#got rid of around 200 observations, but we still have over 6k
```


```{r group by metro area}
#group by metro/micro area and summarize
names(full_dataset_clean)
str(full_dataset_clean)

dataset_grouped <- full_dataset_clean %>%
  group_by(cbsa_title, area_type)%>%
  summarise(
    total_households = sum(total_households, na.rm = TRUE),
    avg_pct_white = mean(pct_white, na.rm = TRUE),
    avg_pct_black = mean(pct_black, na.rm = TRUE),
    avg_pct_asian = mean(pct_asian, na.rm = TRUE),
    avg_pct_married_couple = mean(pct_married_couple, na.rm = TRUE),
    avg_pct_female_householder = mean(pct_female_householder, na.rm = TRUE),
    avg_pct_unemployed = mean(pct_unemployed, na.rm = TRUE),
    avg_pct_below_poverty = mean(pct_below_poverty, na.rm = TRUE),
    avg_pct_bachelors_or_higher = mean(pct_bachelors_or_higher, na.rm = TRUE),
    avg_pct_income_75k_plus = mean(pct_income_75k_plus, na.rm = TRUE),
    total_housing_units = sum(total_housing_units, na.rm = TRUE),
    avg_pct_owner_occupied = mean(pct_owner_occupied, na.rm = TRUE),
    avg_pct_units_built_2000_plus = mean(pct_units_built_2000_plus, na.rm = TRUE),
    avg_pct_vacant_units = mean(pct_vacant_units, na.rm = TRUE),
    avg_median_listing_price = mean(median_listing_price, na.rm = TRUE),
    avg_log_median_listing_price = mean(log_median_listing_price, na.rm = TRUE),
    total_active_listing_count = sum(active_listing_count, na.rm = TRUE),
    avg_median_days_on_market = mean(median_days_on_market, na.rm = TRUE),
    total_new_listing_count = sum(new_listing_count, na.rm = TRUE),
    total_price_increased_count = sum(price_increased_count, na.rm = TRUE),
    avg_price_increased_share = mean(price_increased_share, na.rm = TRUE),
    total_price_reduced_count = sum(price_reduced_count, na.rm = TRUE),
    avg_price_reduced_share = mean(price_reduced_share, na.rm = TRUE),
    total_pending_listing_count = sum(pending_listing_count, na.rm = TRUE),
    avg_median_listing_price_per_square_foot = mean(median_listing_price_per_square_foot, na.rm = TRUE),
    avg_median_square_feet = mean(median_square_feet, na.rm = TRUE),
    avg_average_listing_price = mean(average_listing_price, na.rm = TRUE),
    total_listing_count = sum(total_listing_count, na.rm = TRUE),
    avg_pending_ratio = mean(pending_ratio, na.rm = TRUE)) %>%
  ungroup()

print(dataset_grouped)
```

EDA


```{r dist price}
ggplot(inventory_2024_filtered, aes(x = median_listing_price_per_square_foot)) +
  geom_histogram(binwidth = 50, fill = "steelblue", color = "black") +
  labs(
    title = "Distribution of Median Listing Price per Square Foot",
    x = "Median Price per Square Foot",
    y = "Count") +
  theme_minimal()
```


```{r dist log price}
ggplot(inventory_2024_filtered, aes(x = log_median_price_sqft)) +
  geom_histogram(binwidth = 0.1, fill = "steelblue", color = "black") +
  labs(
    title = "Distribution of Log Median Listing Price per Square Foot",
    x = "Log Median Price per Square Foot",
    y = "Count") +
  theme_minimal()
```

```{r housing count violin}
ggplot(inventory_2024_filtered, aes(x = "", y = total_listing_count)) +
  geom_violin(fill = "lightblue", color = "steelblue", alpha = 0.7) +
  geom_jitter(width = 0.1, alpha = 0.3, color = "darkblue") + 
  labs(
    title = "Distribution of Total Listing Count",
    x = "",
    y = "Total Listings") +
  theme_minimal()

```


```{r log housing count violin}
ggplot(inventory_2024_filtered, aes(x = "", y = total_listing_count)) +
  geom_violin(fill = "lightblue", color = "steelblue", alpha = 0.7) +
  geom_jitter(width = 0.1, alpha = 0.3, color = "darkblue") +
  scale_y_log10() +
  labs(
    title = "Distribution of Total Listing Count (Log Scale)",
    x = "",
    y = "Total Listings (log scale)") +
  theme_minimal()


```


```{r EDA price vs supply}
ggplot(inventory_2024_filtered, aes(x = total_listing_count, y = median_listing_price_per_square_foot)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Total Supply",
    x = "Total Listing Count",
    y = "Median Price per Square Foot") +
  theme_minimal()
```

```{r EDA log price vs supply}
ggplot(inventory_2024_filtered, aes(x = total_listing_count, y = log_median_price_sqft)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Total Supply",
    x = "Total Listing Count",
    y = "Median Price per Square Foot") +
  theme_minimal()
```

```{r EDA price vs demand}
ggplot(inventory_2024_filtered, aes(x = pending_ratio, y = median_listing_price_per_square_foot)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Market Tightness (Demand)",
    x = "Pending Ratio (Pending / Active Listings)",
    y = "Median Price per Square Foot") +
  theme_minimal()
```


```{r EDA price vs demand}
ggplot(inventory_2024_filtered, aes(x = pending_ratio, y = log_median_price_sqft)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Market Tightness (Demand)",
    x = "Pending Ratio (Pending / Active Listings)",
    y = "Median Price per Square Foot") +
  theme_minimal()
```


```{r EDA price vs pending_ratio}
ggplot(inventory_2024_filtered, aes(x = pending_ratio, y = median_listing_price_per_square_foot)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Pending Ratio",
    x = "Pending Ratio",
    y = "Median Price per Square Foot") +
  theme_minimal()
```


```{r EDA price vs pending_ratio}
ggplot(inventory_2024_filtered, aes(x = pending_ratio, y = log_median_price_sqft)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Pending Ratio",
    x = "Pending Ratio",
    y = "Median Price per Square Foot") +
  theme_minimal()
```



```{r EDA price vs median_days_on_market}
ggplot(inventory_2024_filtered, aes(x = median_days_on_market, y = median_listing_price_per_square_foot)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Market Speed",
    x = "Median Days on Market",
    y = "Median Price per Square Foot") +
  theme_minimal()
```


```{r EDA price vs median_days_on_market}
ggplot(inventory_2024_filtered, aes(x = median_days_on_market, y = log_median_price_sqft)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  labs(
    title = "Price vs Market Speed",
    x = "Median Days on Market",
    y = "Median Price per Square Foot") +
  theme_minimal()
```



```{r vars w highest correlations}
#eda
summary(dataset_grouped)
names(dataset_grouped)

#numeric vars for corr plot 
numeric_vars <- dataset_grouped %>%
  select(where(is.numeric))

#define price/supply variables
target_vars <- c("avg_median_listing_price",
                 "avg_log_median_listing_price",
                 "total_active_listing_count",
                 "avg_median_days_on_market",
                 "total_new_listing_count",
                 "total_price_increased_count",
                 "avg_price_increased_share",
                 "total_price_reduced_count",
                 "avg_price_reduced_share",
                 "total_pending_listing_count",
                 "avg_median_listing_price_per_square_foot",
                 "avg_median_square_feet",
                 "avg_average_listing_price",
                 "total_listing_count",
                 "avg_pending_ratio")

cor_matrix <- cor(numeric_vars, use = "pairwise.complete.obs")

#correlation matrix to tidy format
cor_tidy <- as.data.frame(as.table(cor_matrix)) %>%
  rename(var1 = Var1, var2 = Var2, correlation = Freq) %>%
  #only correlations where one of the variables is a target
  filter(var1 %in% target_vars | var2 %in% target_vars) %>%
  filter(var1 != var2) %>%                  #remove self-correlation
  mutate(abs_corr = abs(correlation)) %>%   #absolute correlation
  arrange(desc(abs_corr))                   #sort descending

#top correlations with price/supply variables
head(cor_tidy, 20)

#this is not helpful output. I've tried a few different corr plots and none of them are great because there are too many variables and they often correlate with variables that are just slight variations. I think we skip this in the actual presentation/ report, but keeping so y'all can see that it was attempted
```


```{r scatter- median price vs total listings}
#median price vs total listings
ggplot(dataset_grouped, aes(x = total_listing_count, y = avg_median_listing_price)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "blue") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Median Listing Price vs Total Listings",
       x = "Total Listing Count",
       y = "Average Median Listing Price")
```




```{r scatter- log median price vs active listings}
#log median price vs active listings
ggplot(dataset_grouped, aes(x = total_active_listing_count, y = avg_log_median_listing_price)) +
  geom_point(alpha = 0.6, color = "red") +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Log Median Listing Price vs Active Listings",
       x = "Total Active Listing Count",
       y = "Average Log Median Listing Price")
```



```{r box- metro area type}
#total listings by area type
ggplot(dataset_grouped, aes(x = area_type, y = total_listing_count)) +
  geom_boxplot(fill = "orange") +
  labs(title = "Total Listing Count by Area Type",
       x = "Area Type", y = "Total Listing Count")
```

```{r box- top 5 metrp}
#compare different metros (top 5 by total listings)
top_metros <- full_dataset %>%
  filter(area_type == "Metro") %>%
  group_by(cbsa_title) %>%
  summarise(total_listings = sum(total_listing_count, na.rm = TRUE)) %>%
  arrange(desc(total_listings)) %>%
  slice_head(n = 5) %>%
  pull(cbsa_title)

ggplot(full_dataset %>% filter(cbsa_title %in% top_metros),
       aes(x = cbsa_title, y = median_listing_price)) +
  geom_boxplot(fill = "lightblue") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Median Listing Price in Top 5 Metro Areas",
       x = "Metro Area", y = "Median Listing Price") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


```{r box- bottom 5 metro}
#compare different metros (bottom 5 by total listings)
bottom_metros <- full_dataset %>%
  filter(area_type == "Metro") %>%
  group_by(cbsa_title) %>%
  summarise(total_listings = sum(total_listing_count, na.rm = TRUE)) %>%
  arrange(total_listings) %>%
  slice_head(n = 5) %>%
  pull(cbsa_title)

ggplot(full_dataset %>% filter(cbsa_title %in% bottom_metros),
       aes(x = cbsa_title, y = median_listing_price)) +
  geom_boxplot(fill = "salmon") +
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Median Listing Price in Bottom 5 Metro Areas",
       x = "Metro Area", y = "Median Listing Price") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r box- top and bottom 5 metro}
#top 5 metros by total listings
top_metros <- full_dataset %>%
  filter(area_type == "Metro") %>%
  group_by(cbsa_title) %>%
  summarise(total_listings = sum(total_listing_count, na.rm = TRUE)) %>%
  arrange(desc(total_listings)) %>%
  slice_head(n = 5) %>%
  pull(cbsa_title)

#bottom 5 metros by total listings
bottom_metros <- full_dataset %>%
  filter(area_type == "Metro") %>%
  group_by(cbsa_title) %>%
  summarise(total_listings = sum(total_listing_count, na.rm = TRUE)) %>%
  arrange(total_listings) %>%
  slice_head(n = 5) %>%
  pull(cbsa_title)

#combine top and bottom metros into one dataset
combined_metros <- full_dataset %>%
  filter(cbsa_title %in% c(top_metros, bottom_metros)) %>%
  mutate(listing_group = case_when(
    cbsa_title %in% top_metros ~ "Top 5",
    cbsa_title %in% bottom_metros ~ "Bottom 5"))

#plot
ggplot(combined_metros, aes(x = cbsa_title, y = median_listing_price, fill = listing_group)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::comma) +
  scale_fill_manual(values = c("Top 5" = "lightblue", "Bottom 5" = "salmon")) +
  labs(
    title = "Median Listing Price: Top and Bottom 5 Metro Areas",
    x = "Metro Area",
    y = "Median Listing Price",
    fill = "Listing Group"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


```{r}
#modeling/ statistical analysis 
#basic regression 
names(dataset_grouped)
#reg d- "avg_log_median_listing_price" i- "total_active_listing_count" 
reg_model_1 <- lm(avg_log_median_listing_price ~ total_active_listing_count,
            data = dataset_grouped)

summary(reg_model_1)

#reg d- "avg_log_median_listing_price" i- "total_active_listing_count" "area_type" "avg_pct_income_75k_plus" "avg_pct_units_built_2000_plus" "avg_pct_bachelors_or_higher" 
 
 

#random forest 
```


#data manipulation 
-factor household rank 
EDA- summary statistics 
EDA- graphing different target vars against eachother (i.e. price vs supply, price vs demand, price vs pending_ratio, price vs median_days_on_market) (baylee)
Modeling- linear regressions
-- probably lots of options here 
Modeling- regression tree
Modeling- regression forest
Modeling- lasso regression





